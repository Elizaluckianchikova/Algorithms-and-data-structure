{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elizaluckianchikova/Algorithms-and-data-structure/blob/main/Lab2_DL_part3_poetry_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U00RfKi-RP8P"
      },
      "source": [
        "## Lab 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxQYX5sZRP8V"
      },
      "source": [
        "### Part 3. Poetry generation\n",
        "\n",
        "Let's try to generate some poetry using RNNs.\n",
        "\n",
        "You have several choices here:\n",
        "\n",
        "* The Shakespeare sonnets, file `sonnets.txt` available in the notebook directory.\n",
        "\n",
        "* Роман в стихах \"Евгений Онегин\" Александра Сергеевича Пушкина. В предобработанном виде доступен по [ссылке](https://github.com/attatrol/data_sources/blob/master/onegin.txt).\n",
        "\n",
        "* Some other text source, if it will be approved by the course staff.\n",
        "\n",
        "Text generation can be designed in several steps:\n",
        "    \n",
        "1. Data loading.\n",
        "2. Dictionary generation.\n",
        "3. Data preprocessing.\n",
        "4. Model (neural network) training.\n",
        "5. Text generation (model evaluation).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "XYJV1d_iRP8X"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaKnNY45RP8c"
      },
      "source": [
        "### Data loading: Shakespeare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gvDh-4HRP8d"
      },
      "source": [
        "Shakespeare sonnets are awailable at this [link](http://www.gutenberg.org/ebooks/1041?msg=welcome_stranger). In addition, they are stored in the same directory as this notebook (`sonnetes.txt`). Simple preprocessing is already done for you in the next cell: all technical info is dropped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "collapsed": true,
        "id": "bgQal70-RP8e"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('sonnets.txt'):\n",
        "    !wget https://raw.githubusercontent.com/girafe-ai/ml-course/22f_basic/homeworks/lab02_deep_learning/sonnets.txt\n",
        "\n",
        "with open('sonnets.txt', 'r') as iofile:\n",
        "    text = iofile.readlines()\n",
        "\n",
        "TEXT_START = 45\n",
        "TEXT_END = -368\n",
        "text = text[TEXT_START : TEXT_END]\n",
        "assert len(text) == 2616"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJxddj6FRP8f"
      },
      "source": [
        "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
        "\n",
        "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSxwkHN5RP8g",
        "outputId": "d72ef5ec-d113-46be-b99b-f3825cb2f1a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK!\n"
          ]
        }
      ],
      "source": [
        "# Join all the strings into one and lowercase it\n",
        "# Put result into variable text.\n",
        "\n",
        "# Your great code here\n",
        "import os\n",
        "import string\n",
        "\n",
        "if not os.path.exists('sonnets.txt'):\n",
        "    !wget https://raw.githubusercontent.com/girafe-ai/ml-course/22f_basic/homeworks/lab02_deep_learning/sonnets.txt\n",
        "\n",
        "with open('sonnets.txt', 'r') as iofile:\n",
        "    text = iofile.readlines()\n",
        "\n",
        "TEXT_START = 45\n",
        "TEXT_END = -368\n",
        "text = text[TEXT_START : TEXT_END]\n",
        "assert len(text) == 2616 # Join all the strings into one and lowercase it\n",
        "# Put result into variable text.\n",
        "\n",
        "# Your great code here\n",
        "text = ''.join(text).lower()  # Объединяем строки и переводим в нижний регистр\n",
        "\n",
        "assert len(text) == 100225, 'Are you sure you have concatenated all the strings?'\n",
        "assert not any([x in set(text) for x in string.ascii_uppercase]), 'Uppercase letters are present'\n",
        "print('OK!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr0V5IiJRP8i"
      },
      "source": [
        "### Data loading: \"Евгений Онегин\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2o2UC45RP8n",
        "outputId": "824e5e73-d30c-494a-9a72-ccb1e3ef1a32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-09 14:05:35--  https://raw.githubusercontent.com/attatrol/data_sources/master/onegin.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 262521 (256K) [text/plain]\n",
            "Saving to: ‘onegin.txt’\n",
            "\n",
            "onegin.txt          100%[===================>] 256.37K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-06-09 14:05:36 (1.90 MB/s) - ‘onegin.txt’ saved [262521/262521]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/attatrol/data_sources/master/onegin.txt\n",
        "\n",
        "with open('onegin.txt', 'r') as iofile:\n",
        "    text = iofile.readlines()\n",
        "\n",
        "text = [x.replace('\\t\\t', '') for x in text]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KB9u7JIaRP8o"
      },
      "source": [
        "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
        "\n",
        "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxOgyYsvRP8q",
        "outputId": "5fa98a7a-9b5f-4f3f-edfa-bbdad6294419"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-09 14:05:36--  https://raw.githubusercontent.com/attatrol/data_sources/master/onegin.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 262521 (256K) [text/plain]\n",
            "Saving to: ‘onegin.txt.1’\n",
            "\n",
            "onegin.txt.1        100%[===================>] 256.37K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-06-09 14:05:36 (1.93 MB/s) - ‘onegin.txt.1’ saved [262521/262521]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Join all the strings into one and lowercase it\n",
        "# Put result into variable text.\n",
        "import os\n",
        "import string\n",
        "\n",
        "!wget https://raw.githubusercontent.com/attatrol/data_sources/master/onegin.txt\n",
        "\n",
        "with open('onegin.txt', 'r') as iofile:\n",
        "    text = iofile.readlines()\n",
        "\n",
        "text = [x.replace('\\t\\t', '') for x in text]\n",
        "\n",
        "# Объединяем строки и переводим в нижний регистр\n",
        "text = ''.join(text).lower()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEaxriotRP8r"
      },
      "source": [
        "Put all the characters, that you've seen in the text, into variable `tokens`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEU4rsZ7RP8r",
        "outputId": "28d29e02-eba7-407e-ceea-3dc3ac721591"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-09 14:05:36--  https://raw.githubusercontent.com/attatrol/data_sources/master/onegin.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 262521 (256K) [text/plain]\n",
            "Saving to: ‘onegin.txt.2’\n",
            "\n",
            "onegin.txt.2        100%[===================>] 256.37K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-06-09 14:05:36 (1.93 MB/s) - ‘onegin.txt.2’ saved [262521/262521]\n",
            "\n",
            "Всего уникальных символов: 83\n",
            "['\\n', ' ', '!', '(', ')', ',', '-', '.', '5', '7', '8', '9', ':', ';', '?', '[', ']', '^', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '«', '»', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я', 'ё', '–', '—', '’', '…', '€']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import string\n",
        "\n",
        "!wget https://raw.githubusercontent.com/attatrol/data_sources/master/onegin.txt\n",
        "\n",
        "with open('onegin.txt', 'r') as iofile:\n",
        "    text = iofile.readlines()\n",
        "\n",
        "text = [x.replace('\\t\\t', '') for x in text]\n",
        "text = ''.join(text).lower()\n",
        "\n",
        "# Создаем множество уникальных символов\n",
        "tokens = sorted(set(text))\n",
        "\n",
        "print(f\"Всего уникальных символов: {len(tokens)}\")\n",
        "print(tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hInlALQRP8s"
      },
      "source": [
        "Create dictionary `token_to_idx = {<char>: <index>}` and dictionary `idx_to_token = {<index>: <char>}`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qNeuppZ5RP8t",
        "outputId": "a708045e-66ab-427b-c96e-faf321dcdad5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Символ: е\n",
            "One-hot вектор:\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "# dict <index>:<char>\n",
        "# Your great code here\n",
        "\n",
        "# dict <char>:<index>\n",
        "# Your great code here\n",
        "import os\n",
        "import string\n",
        "import numpy as np\n",
        "\n",
        "# ... (код загрузки и обработки текста)\n",
        "\n",
        "# Создаем список всех уникальных символов (токенов)\n",
        "tokens = sorted(list(set(text)))\n",
        "\n",
        "# Создаем словарь char_to_idx\n",
        "char_to_idx = {char: idx for idx, char in enumerate(tokens)}\n",
        "\n",
        "# Функция для создания one-hot векторов\n",
        "def one_hot_encode(char, tokens):\n",
        "    vector = np.zeros(len(tokens), dtype=int)\n",
        "    vector[char_to_idx[char]] = 1\n",
        "    return vector\n",
        "\n",
        "# Пример использования:\n",
        "test_char = 'е'\n",
        "test_vector = one_hot_encode(test_char, tokens)\n",
        "\n",
        "print(f\"Символ: {test_char}\")\n",
        "print(f\"One-hot вектор:\\n{test_vector}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVw0C9okRP8u"
      },
      "source": [
        "*Comment: in this task we have only 38 different tokens, so let's use one-hot encoding.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGx2gpPZRP8u"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peZZZdMQRP8v"
      },
      "source": [
        "Now we want to build and train recurrent neural net which would be able to something similar to Shakespeare's poetry.\n",
        "\n",
        "Let's use vanilla RNN, similar to the one created during the lesson."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "kow-jDm4RP8v"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "k-YWD5bwkLF8"
      },
      "outputs": [],
      "source": [
        "# Define the RNN model (same as before)\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        \"\"\"\n",
        "        Initializes the RNN model.\n",
        "\n",
        "        Args:\n",
        "            input_size: The size of the input vocabulary.\n",
        "            hidden_size: The size of the hidden state.\n",
        "            output_size: The size of the output vocabulary.\n",
        "        \"\"\"\n",
        "        super(RNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # The embedding layer converts one-hot encoded input tokens into dense vectors\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "\n",
        "        # The RNN layer processes the sequence of embedded input tokens\n",
        "        self.rnn = nn.RNN(hidden_size, hidden_size, batch_first=True)\n",
        "\n",
        "        # The fully connected layer maps the hidden state to the output vocabulary\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        \"\"\"\n",
        "        Performs a forward pass through the RNN model.\n",
        "\n",
        "        Args:\n",
        "            input: A batch of one-hot encoded input tokens.\n",
        "            hidden: The initial hidden state of the RNN.\n",
        "\n",
        "        Returns:\n",
        "            output: A batch of output logits.\n",
        "            hidden: The final hidden state of the RNN.\n",
        "        \"\"\"\n",
        "        embedded = self.embedding(input)\n",
        "        output, hidden = self.rnn(embedded, hidden)\n",
        "        output = self.fc(output)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        \"\"\"\n",
        "        Initializes the hidden state of the RNN.\n",
        "\n",
        "        Args:\n",
        "            batch_size: The size of the batch.\n",
        "\n",
        "        Returns:\n",
        "            hidden: The initial hidden state of the RNN.\n",
        "        \"\"\"\n",
        "        return torch.zeros(1, batch_size, self.hidden_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rekOMrHpkgUt"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "input_size = 100\n",
        "hidden_size = 128\n",
        "output_size = 100\n",
        "batch_size = 32\n",
        "sequence_length = 50\n",
        "num_epochs = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Create the model, loss function, and optimizer\n",
        "model = RNN(input_size, hidden_size, output_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Generate some example data (replace this with your actual data loading)\n",
        "def generate_data(batch_size, sequence_length, input_size):\n",
        "    input_data = torch.randint(0, input_size, (batch_size, sequence_length))\n",
        "    target_data = torch.randint(0, input_size, (batch_size, sequence_length))\n",
        "    return input_data, target_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjoVij3mRP8w"
      },
      "source": [
        "Plot the loss function (axis X: number of epochs, axis Y: loss function)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "collapsed": true,
        "id": "Wt9JYLfRRP8w",
        "outputId": "4c774ea5-9cf2-4763-cbbe-3d74a1325eb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 4.6600\n",
            "Epoch [20/100], Loss: 4.6376\n",
            "Epoch [30/100], Loss: 4.6419\n",
            "Epoch [40/100], Loss: 4.6374\n",
            "Epoch [50/100], Loss: 4.6280\n",
            "Epoch [60/100], Loss: 4.6296\n",
            "Epoch [70/100], Loss: 4.6218\n",
            "Epoch [80/100], Loss: 4.6272\n",
            "Epoch [90/100], Loss: 4.6202\n",
            "Epoch [100/100], Loss: 4.6266\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Your plot code here\n",
        "# Training loop\n",
        "losses = []\n",
        "for epoch in range(num_epochs):\n",
        "    # Generate a batch of data\n",
        "    input_data, target_data = generate_data(batch_size, sequence_length, input_size)\n",
        "\n",
        "    # Initialize hidden state\n",
        "    hidden = model.init_hidden(batch_size)\n",
        "\n",
        "    # Zero the gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    output, hidden = model(input_data, hidden)\n",
        "\n",
        "    # Reshape output and target for CrossEntropyLoss\n",
        "    output = output.view(-1, output_size)\n",
        "    target_data = target_data.view(-1)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = criterion(output, target_data)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Store loss for plotting\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    # Print progress\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Plot the loss over epochs\n",
        "plt.plot(losses)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6sDlWpFlOKb"
      },
      "source": [
        "### Комментарии\n",
        "\n",
        "Генерация данных:\n",
        "\n",
        "• generate_data(batch_size, sequence_length, input_size): эта функция генерирует пакет данных, который содержит последовательности входных данных и соответствующие им выходные данные. Пакет данных имеет форму (batch_size, sequence_length, input_size) для входных данных и (batch_size, sequence_length) для выходных данных.\n",
        "\n",
        "Инициализация скрытого состояния:\n",
        "\n",
        "• hidden = model.init_hidden(batch_size): эта строка инициализирует скрытое состояние модели RNN нулевыми тензорами. Скрытое состояние имеет форму (1, batch_size, hidden_size), где 1 - количество слоев RNN.\n",
        "\n",
        "Обнуление градиентов:\n",
        "\n",
        "• optimizer.zero_grad(): эта строка обнуляет градиенты модели. Градиенты должны быть обнулены перед каждым обратным проходом, чтобы избежать накопления градиентов из предыдущих проходов.\n",
        "\n",
        "Прямой проход:\n",
        "\n",
        "• output, hidden = model(input_data, hidden): эта строка выполняет прямой проход через модель RNN. input_data - это пакет входных данных, а hidden - это скрытое состояние. Функция model возвращает выходные данные output и обновленное скрытое состояние hidden.\n",
        "\n",
        "Преобразование выходных данных и целевых данных:\n",
        "\n",
        "• output = output.view(-1, output_size): эта строка преобразует выходные данные из формы (batch_size, sequence_length, output_size) в форму (-1, output_size). Это необходимо для использования функции потери CrossEntropyLoss, которая ожидает входные данные в плоском виде.\n",
        "• target_data = target_data.view(-1): эта строка преобразует целевые данные из формы (batch_size, sequence_length) в форму (-1). Это также необходимо для использования функции потери CrossEntropyLoss.\n",
        "\n",
        "Вычисление потерь:\n",
        "\n",
        "• loss = criterion(output, target_data): эта строка вычисляет потерю между выходными данными и целевыми данными с использованием функции потери CrossEntropyLoss.\n",
        "\n",
        "Обратный проход и оптимизация:\n",
        "\n",
        "• loss.backward(): эта строка выполняет обратный проход через модель RNN, вычисляя градиенты потери относительно весов модели.\n",
        "• optimizer.step(): эта строка обновляет веса модели, используя оптимизатор optimizer. Оптимизатор использует градиенты, вычисленные в предыдущем обратном проходе, для обновления весов в направлении, уменьшающем потерю.\n",
        "\n",
        "Сохранение потерь для построения графика:\n",
        "\n",
        "• losses.append(loss.item()): эта строка сохраняет значение потери в списке losses. Этот список будет использоваться для построения графика потери в конце цикла обучения.\n",
        "\n",
        "Вывод прогресса:\n",
        "\n",
        "• if (epoch + 1) % 10 == 0:: этот условный оператор печатает прогресс обучения каждые 10 эпох. Он печатает текущую эпоху, общую потерю и потерю на текущей эпохе.\n",
        "\n",
        "Построение графика потерь:\n",
        "\n",
        "• plt.plot(losses): эта строка строит график потерь на основе знач\n",
        "\n",
        "ений, сохраненных в списке losses. График показывает, как потеря меняется с каждой эпохой.\n",
        "• plt.xlabel('Epoch'): эта строка устанавливает метку оси x в \"Epoch\".\n",
        "• plt.ylabel('Loss'): эта строка устанавливает метку оси y в \"Loss\".\n",
        "• plt.title('Training Loss'): эта строка устанавливает заголовок графика в \"Training Loss\".\n",
        "• plt.show(): эта строка отображает график."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZMcbiyu7RP8x"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# ... (Your RNN model definition from previous responses) ...\n",
        "\n",
        "def generate_sample(char_rnn, tokens, token_to_id, seed_phrase=' Hello', max_length=100, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Generates text given a seed phrase.\n",
        "\n",
        "    Args:\n",
        "        char_rnn: The trained RNN model.\n",
        "        tokens: A list of all possible tokens (characters).\n",
        "        token_to_id: A dictionary mapping tokens to their IDs.\n",
        "        seed_phrase: The initial phrase to start generation.\n",
        "        max_length: Maximum length of the generated text (including seed_phrase).\n",
        "        temperature: Controls the randomness of the generated text.\n",
        "\n",
        "    Returns:\n",
        "        The generated text string.\n",
        "    \"\"\"\n",
        "\n",
        "    # Prepare input sequence\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64)  # Batch dimension added\n",
        "\n",
        "    # Initialize hidden state\n",
        "    hidden = char_rnn.init_hidden(batch_size=1)  # Batch size is 1 for generation\n",
        "\n",
        "    # Feed the seed phrase\n",
        "    for i in range(len(seed_phrase) - 1):\n",
        "        output, hidden = char_rnn(x_sequence[:, i:i+1], hidden)  # Slice input for each timestep\n",
        "\n",
        "    # Generate the rest of the sequence\n",
        "    for _ in range(max_length - len(seed_phrase)):\n",
        "        output, hidden = char_rnn(x_sequence[:, -1:], hidden)  # Input is the last token\n",
        "\n",
        "        # Sample from the output distribution\n",
        "        output_logits = output / temperature\n",
        "        p_next = F.softmax(output_logits, dim=-1).squeeze().numpy()  # Remove batch dimension\n",
        "        next_ix = np.random.choice(len(tokens), p=p_next)\n",
        "\n",
        "        # Append the sampled token to the input sequence\n",
        "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64)\n",
        "        x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n",
        "\n",
        "    # Convert the generated sequence back to text\n",
        "    generated_text = ''.join([tokens[ix] for ix in x_sequence[0].tolist()])  # Remove batch dimension\n",
        "    return generated_text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NtenTbTlnks"
      },
      "source": [
        "Код определяет функцию generate_sample, которая генерирует текст на основе заданной начальной фразы, используя обученную модель RNN. Вот пошаговое описание того, что делает код:\n",
        "\n",
        "1. Подготовка входной последовательности:\n",
        "   - Входная последовательность подготавливается путем преобразования начальной фразы в список идентификаторов токенов с использованием словаря token_to_id.\n",
        "   - Список идентификаторов токенов преобразуется в тензор PyTorch с дополнительным измерением для пакета.\n",
        "\n",
        "2. Инициализация скрытого состояния:\n",
        "   - Исходное скрытое состояние для модели RNN инициализируется с помощью метода init_hidden. Размер пакета устанавливается в 1, поскольку мы генерируем текст по одному символу за раз.\n",
        "\n",
        "3. Обработка начальной фразы:\n",
        "   - Начальная фраза подается в модель RNN по одному символу за раз. Выходные данные и скрытое состояние обновляются на каждом временном шаге.\n",
        "\n",
        "4. Генерация оставшейся части последовательности:\n",
        "   - После обработки начальной фразы оставшиеся символы генерируются с использованием следующего цикла:\n",
        "     - Самый последний выход и скрытое состояние используются для генерации нового распределения вывода.\n",
        "     - Распределение вывода дискретизируется для получения следующего идентификатора символа.\n",
        "     - Следующий идентификатор символа добавляется к входной последовательности.\n",
        "\n",
        "5. Преобразование сгенерированной последовательности в текст:\n",
        "   - Сгенерированная последовательность идентификаторов символов преобразуется обратно в текстовую строку путем сопоставления каждого идентификатора с соответствующим ему символом, используя список tokens.\n",
        "   - Измерение пакета удаляется из сгенерированной последовательности.\n",
        "\n",
        "6. Управление температурой:\n",
        "   - Параметр temperature управляет случайностью генерируемого текста. Более высокая температура приводит к более разнообразному и менее предсказуемому тексту, в то время как более низкая температура приводит к более детерминированному и связному тексту.\n",
        "\n",
        "Функция generate_sample может использоваться для создания креативного текста, такого как стихи или рассказы, путем предоставления начальной фразы и настройки параметра температуры."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ETTpLcB1dFti"
      },
      "outputs": [],
      "source": [
        "\n",
        "def generate_sample(char_rnn, tokens, token_to_id, seed_phrase=' Hello', max_length=100, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Generates text given a seed phrase.\n",
        "\n",
        "    Args:\n",
        "        char_rnn: The trained RNN model.\n",
        "        tokens: A list of all possible tokens (characters).\n",
        "        token_to_id: A dictionary mapping tokens to their IDs.\n",
        "        seed_phrase: The initial phrase to start generation.\n",
        "        max_length: Maximum length of the generated text (including seed_phrase).\n",
        "        temperature: Controls the randomness of the generated text.\n",
        "\n",
        "    Returns:\n",
        "        The generated text string.\n",
        "    \"\"\"\n",
        "\n",
        "    # Prepare input sequence\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64)  # Batch dimension added\n",
        "\n",
        "    # Initialize hidden state\n",
        "    hidden = char_rnn.init_hidden(batch_size=1)  # Batch size is 1 for generation\n",
        "\n",
        "    # Feed the seed phrase\n",
        "    for i in range(len(seed_phrase) - 1):\n",
        "        output, hidden = char_rnn(x_sequence[:, i:i+1], hidden)  # Slice input for each timestep\n",
        "\n",
        "    # Generate the rest of the sequence\n",
        "    for _ in range(max_length - len(seed_phrase)):\n",
        "        output, hidden = char_rnn(x_sequence[:, -1:], hidden)  # Input is the last token\n",
        "\n",
        "        # Sample from the output distribution\n",
        "        output_logits = output / temperature\n",
        "        p_next = F.softmax\n",
        "        # ... (предыдущий код)\n",
        "\n",
        "    # Convert the generated sequence back to text\n",
        "    generated_text = ''.join([tokens[ix] for ix in x_sequence[0].tolist()])  # Remove batch dimension\n",
        "    return generated_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_6SmIHnHRP8x"
      },
      "outputs": [],
      "source": [
        "# An example of generated text.\n",
        "# An example of generated text.\n",
        "# print(generate_text(length=500, temperature=0.2))\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "A3OHAM6st4Ge"
      },
      "outputs": [],
      "source": [
        "# --- Загрузка данных ---\n",
        "\n",
        "with open('onegin.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "# --- Подготовка данных с использованием Word Embeddings ---\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "input_sequences = []\n",
        "for line in text.split('.'):\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "X = input_sequences[:,:-1]\n",
        "y = np.array(input_sequences[:,-1])\n",
        "y = np.eye(total_words)[y]  # One-hot encode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "oUu4sksMuTUx",
        "outputId": "6340d7de-37e6-48fc-cd74-f58c4b832b32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "347/347 [==============================] - 648s 2s/step - loss: 8.2382\n",
            "Epoch 2/50\n",
            "347/347 [==============================] - 633s 2s/step - loss: 7.8403\n",
            "Epoch 3/50\n",
            "347/347 [==============================] - 634s 2s/step - loss: 7.6933\n",
            "Epoch 4/50\n",
            "347/347 [==============================] - 633s 2s/step - loss: 7.5953\n",
            "Epoch 5/50\n",
            "191/347 [===============>..............] - ETA: 4:41 - loss: 7.4619"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-f799edf40039>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# --- Обучение модели LSTM ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mhistory_lstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# --- Создание модели LSTM ---\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(Embedding(total_words, 50, input_length=max_sequence_len-1))\n",
        "model_lstm.add(LSTM(256, return_sequences=True))  # Добавлен параметр return_sequences=True\n",
        "model_lstm.add(Dropout(0.2))\n",
        "model_lstm.add(LSTM(256))\n",
        "model_lstm.add(Dropout(0.2))\n",
        "model_lstm.add(Dense(total_words, activation='softmax'))\n",
        "model_lstm.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# --- Обучение модели LSTM ---\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=10)\n",
        "history_lstm = model_lstm.fit(X, y, batch_size=64, epochs=50, callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oPP0_5evtcd"
      },
      "outputs": [],
      "source": [
        "# --- Функция для построения графиков ---\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Функция для построения графиков ---\n",
        "def plot_graphs(history, history_lstm):\n",
        "    # Построение графика функции потерь\n",
        "    plt.plot(history.history['loss'], label='Vanilla RNN')\n",
        "    plt.plot(history_lstm.history['loss'], label='LSTM')\n",
        "    plt.title('Loss Function Comparison')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Пример использования функции для построения графика\n",
        "# Предполагается, что history и history_lstm - это объекты возвращаемые методом fit модели\n",
        "# plot_graphs(history, history_lstm)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Функция для построения графиков ---\n",
        "def plot_graphs(history, history_lstm):\n",
        "    # Построение графика функции потерь\n",
        "    plt.plot(history.history['loss'], label='Vanilla RNN')\n",
        "    plt.plot(history_lstm.history['loss'], label='LSTM')\n",
        "    plt.title('Loss Function Comparison')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "xGmdRiEnirZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0_L7Qvkvu2W"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --- Генерация текста ---\n",
        "def generate_text(seed_text, next_words=20):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted = model.predict(token_list, verbose=0)\n",
        "        predicted_index = np.argmax(predicted)\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted_index:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Этот код должен быть определен до вызова main()\n",
        "    # X, y, tokenizer, max_sequence_len, total_words = ...\n",
        "    # main(X, y, tokenizer, max_sequence_len, total_words)\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rouge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15jj_Grjl4mi",
        "outputId": "8630c5a9-8919-40c2-f575-b462fae9d9da"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from rouge import Rouge\n",
        "\n",
        "def calculate_bleu_score(reference, candidate):\n",
        "    return sentence_bleu([reference], candidate)\n",
        "\n",
        "def calculate_rouge_score(reference, candidate):\n",
        "    rouge = Rouge()\n",
        "    scores = rouge.get_scores(candidate, reference)\n",
        "    return scores[0]['rouge-l']['f']\n",
        "\n",
        "# Пример использования\n",
        "reference = \"The cat is on the mat.\"\n",
        "candidate = \"The cat is under the mat.\"\n",
        "\n",
        "bleu_score = calculate_bleu_score(reference, candidate)\n",
        "rouge_score = calculate_rouge_score(reference, candidate)\n",
        "\n",
        "print(f\"BLEU Score: {bleu_score}\")\n",
        "print(f\"ROUGE Score: {rouge_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALOZ00wUl7Lq",
        "outputId": "8224e53a-2cf6-4097-ebff-c1f7cfc7f729"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 0.7267072830982378\n",
            "ROUGE Score: 0.8333333283333335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJInOi99uhJt"
      },
      "outputs": [],
      "source": [
        "# --- Функция для генерации текста по словам ---\n",
        "def generate_text(seed_text, next_words=20):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted = model_lstm.predict(token_list, verbose=0)  # Использование модели LSTM\n",
        "        predicted_index = np.argmax(predicted)\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted_index:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKGUBdQZezDO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# --- Загрузка данных ---\n",
        "\n",
        "with open('onegin.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read().replace('\\n', ' ').lower()\n",
        "\n",
        "# --- Подготовка данных с использованием Word Embeddings ---\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "input_sequences = []\n",
        "for line in text.split('.'):\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "X = input_sequences[:,:-1]\n",
        "y = np.array(input_sequences[:,-1])\n",
        "y = np.eye(total_words)[y]  # One-hot encode\n",
        "\n",
        "# --- Создание модели ---\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 200, input_length=max_sequence_len-1))  # Увеличена размерность эмбеддингов\n",
        "model.add(LSTM(256))  # Увеличено количество нейронов в LSTM\n",
        "model.add(Dropout(0.2))  # Добавлен Dropout\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# --- Обучение модели ---\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=10) # Изменено на monitor='loss'\n",
        "model.fit(X, y, batch_size=64, epochs=200, callbacks=[early_stopping])\n",
        "\n",
        "# --- Функция для генерации текста по словам ---\n",
        "def generate_text(seed_text, next_words=20):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted = model.predict(token_list, verbose=0)\n",
        "        predicted_index = np.argmax(predicted)\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted_index:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n",
        "\n",
        "# --- Пример использования ---\n",
        "new_text = generate_text(\"Пример текста\", next_words=10)\n",
        "print(new_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYzbPquBm4ER"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# --- Загрузка данных ---\n",
        "\n",
        "with open('onegin.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# --- Подготовка данных с использованием Word Embeddings ---\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "input_sequences = []\n",
        "for line in text.split('.'):\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "X = input_sequences[:,:-1]\n",
        "y = np.array(input_sequences[:,-1])\n",
        "y = np.eye(total_words)[y]  # One-hot encode\n",
        "\n",
        "# --- Создание модели ---\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 200, input_length=max_sequence_len-1))  # Увеличена размерность эмбеддингов\n",
        "model.add(LSTM(256))  # Увеличено количество нейронов в LSTM\n",
        "model.add(Dropout(0.2))  # Добавлен Dropout\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# --- Обучение модели ---\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=10) # Изменено на monitor='loss'\n",
        "model.fit(X, y, batch_size=64, epochs=200, callbacks=[early_stopping])\n",
        "\n",
        "# --- Функция для генерации текста по словам ---\n",
        "def generate_text(seed_text, next_words=20):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted = model.predict(token_list, verbose=0)\n",
        "        predicted_index = np.argmax(predicted)\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted_index:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n",
        "\n",
        "# --- Пример использования ---\n",
        "new_text = generate_text(\"Пример текста\", next_words=10)\n",
        "print(new_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilU3qd4CRP8z"
      },
      "source": [
        "### More poetic model\n",
        "\n",
        "Let's use LSTM instead of vanilla RNN and compare the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQe1VKaORP8z"
      },
      "source": [
        "Plot the loss function of the number of epochs. Does the final loss become better?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "WaBGU-frRP80"
      },
      "outputs": [],
      "source": [
        "# Your beautiful code here\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# --- Загрузка данных ---\n",
        "\n",
        "with open('onegin.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "# --- Подготовка данных с использованием Word Embeddings ---\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "input_sequences = []\n",
        "for line in text.split('.'):\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "X = input_sequences[:,:-1]\n",
        "y = np.array(input_sequences[:,-1])\n",
        "y = np.eye(total_words)[y]  # One-hot encode\n",
        "\n",
        "\n",
        "# --- Создание модели LSTM ---\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(Embedding(total_words, 200, input_length=max_sequence_len-1))\n",
        "model_lstm.add(LSTM(256, return_sequences=True))  # Добавлен параметр return_sequences=True\n",
        "model_lstm.add(Dropout(0.2))\n",
        "model_lstm.add(LSTM(256))\n",
        "model_lstm.add(Dropout(0.2))\n",
        "model_lstm.add(Dense(total_words, activation='softmax'))\n",
        "model_lstm.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# --- Обучение модели LSTM ---\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=10)\n",
        "history_lstm = model_lstm.fit(X, y, batch_size=64, epochs=200, callbacks=[early_stopping])\n",
        "\n",
        "# ... (Остальной код остается таким же)\n",
        "\n",
        "# --- Функция для генерации текста по словам ---\n",
        "# --- Функция для генерации текста по словам ---\n",
        "def generate_text(seed_text, next_words=20):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted = model_lstm.predict(token_list, verbose=0)  # Использование модели LSTM\n",
        "        predicted_index = np.argmax(predicted)\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted_index:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n",
        "\n",
        "\n",
        "\n",
        "# --- Пример использования ---\n",
        "new_text = generate_text(\"Пример текста\", next_words=10)\n",
        "print(new_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from rouge import Rouge\n",
        "\n",
        "def calculate_bleu_score(reference, candidate):\n",
        "    return sentence_bleu([reference.split()], candidate.split())\n",
        "\n",
        "def calculate_rouge_score(reference, candidate):\n",
        "    rouge = Rouge()\n",
        "    scores = rouge.get_scores(candidate, reference)\n",
        "    return scores[0]['rouge-l']['f']\n",
        "\n",
        "# Пример использования\n",
        "reference = \"The cat is on the mat.\"\n",
        "candidate = \"The cat is under the mat.\"\n",
        "\n",
        "bleu_score = calculate_bleu_score(reference, candidate)\n",
        "rouge_score = calculate_rouge_score(reference, candidate)\n",
        "\n",
        "print(f\"BLEU Score: {bleu_score}\")\n",
        "print(f\"ROUGE Score: {rouge_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jS4ROzX1plFB",
        "outputId": "7310bb5a-4b6e-4e11-b3ad-f5114240c8d9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 7.262123179505913e-78\n",
            "ROUGE Score: 0.8333333283333335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdKNAznoRP80"
      },
      "source": [
        "Generate text using the trained net with different `temperature` parameter: `[0.1, 0.2, 0.5, 1.0, 2.0]`.\n",
        "\n",
        "Evaluate the results visually, try to interpret them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "0WpeTjtZRP81"
      },
      "outputs": [],
      "source": [
        "# Text generation with different temperature values here\n",
        "import numpy as np\n",
        "\n",
        "# Assuming model is defined and trained outside of this function\n",
        "# model = ...\n",
        "\n",
        "def generate_text(seed_text, next_words=20, temperature=1.0):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted_probs = model.predict(token_list, verbose=0)\n",
        "\n",
        "        # Apply temperature to the predicted probabilities\n",
        "        predicted_probs = np.log(predicted_probs) / temperature\n",
        "        predicted_probs = np.exp(predicted_probs)\n",
        "        predicted_probs /= np.sum(predicted_probs)\n",
        "\n",
        "        # Sample the next word based on the adjusted probabilities\n",
        "        predicted_index = np.random.choice(range(total_words), p=predicted_probs.ravel())\n",
        "\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted_index:\n",
        "                output_word = word\n",
        "                break\n",
        "\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n",
        "\n",
        "# Now you can generate text with different temperatures\n",
        "temperatures = [0.1, 0.2, 0.5, 1.0, 2.0]\n",
        "for temperature in temperatures:\n",
        "    generated_text = generate_text(seed_text=\"This is a sample seed text\", temperature=temperature)\n",
        "    print(f\"Generated text with temperature {temperature}:\\n{generated_text}\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyO-VAQHRP81"
      },
      "source": [
        "### Saving and loading models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSt_gMxyRP81"
      },
      "source": [
        "Save the model to the disk, then load it and generate text. Examples are available [here](https://pytorch.org/tutorials/beginner/saving_loading_models.html])."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jEtaf4zNRP82"
      },
      "outputs": [],
      "source": [
        "# Saving and loading code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kw7r_UcdRP82"
      },
      "source": [
        "### References\n",
        "1. <a href='http://karpathy.github.io/2015/05/21/rnn-effectiveness/'> Andrew Karpathy blog post about RNN. </a>\n",
        "There are several examples of genration: Shakespeare texts, Latex formulas, Linux Sourse Code and children names.\n",
        "2. <a href='https://github.com/karpathy/char-rnn'> Repo with char-rnn code </a>\n",
        "3. Cool repo with PyTorch examples: [link](https://github.com/spro/practical-pytorch`)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}